# üìä Analiza Projektu GPW Scraper - Dog≈Çƒôbne Zrozumienie

**Data:** 9 listopada 2025  
**Autor analizy:** GitHub Copilot  
**Wersja projektu:** 2.0 (baza danych MySQL)

---

## üéØ Twoje Wymagania (Cel Biznesowy)

### Tryb 1: Scraping Manualny (jednorazowy)
**U≈ºytkownik wpisuje parametry ‚Üí pobiera raporty ‚Üí generuje streszczenia**

1. **Input od u≈ºytkownika:**
   - Nazwa sp√≥≈Çki (np. "Asseco")
   - Zakres dat (od - do)
   - Parametry filtrowania (typ raportu, kategoria)

2. **Proces:**
   - Scraping strony GPW ‚Üí pobieranie raport√≥w (PDF/HTML)
   - Dla **ka≈ºdego pojedynczego raportu**: lokalny LLM generuje **pojedyncze streszczenie**
   - Na podstawie **wszystkich pojedynczych streszcze≈Ñ**: LLM tworzy **jedno du≈ºe zbiorcze streszczenie**

3. **Output:**
   - **Pojedyncze streszczenia** ‚Üí zapisane gdzie≈õ (plik .md lub baza)
   - **Du≈ºe zbiorcze streszczenie** ‚Üí **PDF** + zapis w bazie
   - U≈ºytkownik dostaje wynik od razu w UI

### Tryb 2: Scraping Okresowy (CRON)
**System automatycznie, co jaki≈õ czas, scrapuje sp√≥≈Çkƒô i generuje streszczenia**

1. **Konfiguracja CRON:**
   - U≈ºytkownik ustawia: sp√≥≈Çkƒô, harmonogram (np. co tydzie≈Ñ), model LLM
   - System zapisuje konfiguracjƒô

2. **Proces (automatyczny, w tle):**
   - CRON uruchamia scraping zgodnie z harmonogramem
   - Pobiera **nowe raporty** od ostatniego uruchomienia
   - Dla ka≈ºdego nowego raportu ‚Üí **pojedyncze streszczenie** (LLM)
   - Na podstawie wszystkich streszcze≈Ñ ‚Üí **du≈ºe zbiorcze streszczenie** dla tego uruchomienia

3. **Output:**
   - **Pojedyncze streszczenia** ‚Üí zapisane gdzie≈õ
   - **Du≈ºe zbiorcze streszczenie** ‚Üí **PDF** + zapis w bazie

4. **Dodatkowa funkcja (META-ANALIZA):**
   - Je≈õli system ma **co najmniej 2 du≈ºe zbiorcze streszczenia** (z r√≥≈ºnych uruchomie≈Ñ CRON):
     - LLM analizuje **wszystkie du≈ºe streszczenia** razem
     - Generuje **meta-raport**: "Jak wiedzie siƒô sp√≥≈Çce w czasie?"
     - Format: PDF + zapis w bazie

---

## üì¶ Co Jest Ju≈º Zrobione (Stan Obecny)

### ‚úÖ Co Dzia≈Ça:

#### 1. **Scraping Manualny** (Tryb 1) - **80% gotowe**
- ‚úÖ Interface Gradio (`app.py`) - zak≈Çadka "Scraping"
- ‚úÖ Pobieranie raport√≥w z GPW (`scrape_script.py`)
- ‚úÖ Pobieranie za≈ÇƒÖcznik√≥w (PDF, HTML)
- ‚úÖ Generowanie **pojedynczych streszcze≈Ñ** przez LLM (`summary.py`)
  - U≈ºywa K-means clustering do wyciƒÖgania kluczowych fragment√≥w
  - Model Ollama (llama3.2, gemma, qwen2.5)
- ‚úÖ Zapis do bazy MySQL:
  - Firma (`companies`)
  - Raporty (`reports`)
  - Historia wyszukiwa≈Ñ (`search_history`)
  - Pobrane pliki (`downloaded_files`) z deduplikacjƒÖ MD5
- ‚úÖ **Zbiorczy raport Markdown** (`generate_summary_report()` w `scrape_script.py`)
  - Tworzy plik `.md` w `SUMMARY_REPORTS/`
  - Zawiera: metadatƒô, listƒô raport√≥w, wszystkie streszczenia z LLM
  - Zapisuje metadata do `summary_reports` w bazie

#### 2. **Scraping Okresowy** (Tryb 2) - **70% gotowe**
- ‚úÖ ZarzƒÖdzanie konfiguracjami (`config_manager.py`)
  - Zapis/odczyt z bazy `scheduled_jobs`
  - Parametry: firma, daty, model, harmonogram cron
- ‚úÖ Instalacja zada≈Ñ CRON (`cron_manager.py`)
  - Automatyczne dodawanie do systemowego crontab
  - Walidacja wyra≈ºe≈Ñ cron
- ‚úÖ Skrypt wykonawczy (`run_scheduled.py`)
  - Uruchamiany przez CRON
  - ≈Åaduje konfiguracjƒô, wywo≈Çuje `scrape()`
  - Zapisuje wyniki do `scheduled_results/`
  - Loguje wykonanie do `job_execution_log` w bazie
- ‚úÖ Interface Gradio - zak≈Çadka "Harmonogram"
  - Tworzenie/usuwanie konfiguracji
  - Instalacja/usuniƒôcie z crontab
  - PodglƒÖd aktywnych zada≈Ñ
- ‚úÖ Zak≈Çadka "Zbiorcze Raporty"
  - PrzeglƒÖdanie wygenerowanych raport√≥w
  - Filtrowanie po firmie/zadaniu
  - PodglƒÖd tre≈õci

### ‚ùå Czego Brakuje:

#### 1. **Format PDF dla zbiorczego streszczenia**
- **Obecny stan:** Zbiorczy raport jest zapisywany jako **Markdown** (`.md`)
- **Twoje wymaganie:** Zbiorczy raport ma byƒá w **PDF**
- **Co trzeba zrobiƒá:**
  - Dodaƒá konwersjƒô `.md` ‚Üí `.pdf` (np. biblioteka `markdown`, `pdfkit`, `weasyprint`)
  - Lub: generowaƒá PDF bezpo≈õrednio (np. `reportlab`, `fpdf`)

#### 2. **Zapis pojedynczych streszcze≈Ñ**
- **Obecny stan:** 
  - Pojedyncze streszczenia sƒÖ generowane (`get_summaries()`)
  - SƒÖ **wy≈õwietlane w UI** i **wstawiane do zbiorczego raportu MD**
  - **NIE sƒÖ zapisywane osobno** jako pliki ani w dedykowanym polu bazy
- **Twoje wymaganie:** Pojedyncze streszczenia majƒÖ byƒá zapisywane (plik .md lub baza)
- **Co trzeba zrobiƒá:**
  - **Opcja A:** Zapisywaƒá ka≈ºde pojedyncze streszczenie jako osobny plik `.md` w folderze (np. `SUMMARY_REPORTS/single/`)
  - **Opcja B:** Zapisywaƒá do bazy - w tabeli `downloaded_files` jest ju≈º kolumna `summary_text` (LONGTEXT) - **TO JU≈ª ISTNIEJE!**
  - **Rekomendacja:** Wykorzystaj istniejƒÖcƒÖ kolumnƒô `summary_text` w `downloaded_files` ‚Äî to najprostsze

#### 3. **META-ANALIZA (dla Trybu 2)**
- **Obecny stan:** **Nie istnieje**
- **Twoje wymaganie:** 
  - Gdy sƒÖ ‚â•2 du≈ºe zbiorcze streszczenia (z r√≥≈ºnych uruchomie≈Ñ CRON)
  - System automatycznie tworzy meta-raport: analiza trendu sp√≥≈Çki w czasie
- **Co trzeba zrobiƒá:**
  - Nowa funkcja: `generate_meta_report(company, summary_report_ids)`
  - Pobiera wszystkie du≈ºe streszczenia z bazy (`summary_reports`)
  - Wysy≈Ça je do LLM z promptem: "Przeanalizuj te raporty i opisz jak wiedzie siƒô firmie w czasie"
  - Zapisuje jako osobny typ raportu (PDF + baza)

#### 4. **Drobne poprawki:**
- ‚ùå Pojedyncze streszczenia NIE sƒÖ obecnie zapisywane do `downloaded_files.summary_text` (kod wywo≈Çuje `insert_downloaded_file` ale z `is_summarized=False` i bez `summary_text`)
- ‚ùå Format daty w bazie by≈Ç b≈Çƒôdny (ale to **ju≈º naprawione** dzisiaj)
- ‚ùå Brak pakietu `tabulate` (ale to **ju≈º naprawione** dzisiaj)

---

## üîç Jak Obecnie Dzia≈Ça System (Techniczne)

### Przep≈Çyw Tryb 1 (Manualny):
```
U≈ºytkownik wype≈Çnia formularz w Gradio
         ‚Üì
app.py: run_scrape_ui()
         ‚Üì
scrape_script.py: scrape()
         ‚Üì
1. Pobiera HTML z GPW (BeautifulSoup)
2. Parsuje listƒô raport√≥w
3. Pobiera za≈ÇƒÖczniki (PDF/HTML)
4. Dla ka≈ºdego pliku:
   - Wczytuje PDF/HTML
   - summary.py: summarize_document_with_kmeans_clustering()
     ‚Üí K-means clustering ‚Üí LLM ‚Üí pojedyncze streszczenie
5. generate_summary_report():
   - Tworzy plik .md z:
     * Metadane (firma, daty, liczba raport√≥w)
     * Tabela raport√≥w (DataFrame.to_markdown())
     * Wszystkie pojedyncze streszczenia
   - Zapisuje do SUMMARY_REPORTS/
   - Zapisuje metadata do bazy (summary_reports)
6. Zwraca wyniki do UI
```

### Przep≈Çyw Tryb 2 (CRON):
```
U≈ºytkownik tworzy konfiguracjƒô w UI
         ‚Üì
config_manager.py: save_config()
         ‚Üì
Zapis do bazy: scheduled_jobs
         ‚Üì
U≈ºytkownik klika "Zainstaluj do crontab"
         ‚Üì
cron_manager.py: install_jobs()
         ‚Üì
Dodaje wpis do systemowego crontab:
  "0 9 * * 1 /path/to/python run_scheduled.py job_name >> logs/job_name.log"
         ‚Üì
--- W zaplanowanym czasie ---
         ‚Üì
CRON uruchamia: run_scheduled.py job_name
         ‚Üì
1. ≈Åaduje konfiguracjƒô z bazy (scheduled_jobs)
2. Wywo≈Çuje scrape() (IDENTYCZNIE jak Tryb 1)
3. Zapisuje wyniki:
   - Plik tekstowy: scheduled_results/job_name_timestamp.txt
   - Metadata: job_execution_log (status, liczba raport√≥w)
4. Aktualizuje statystyki: scheduled_jobs (last_run, run_count)
```

### Baza Danych (MySQL - struktura v2.0):
```
companies          - Sp√≥≈Çki GPW (id, nazwa, sektor)
   ‚Üì (FK)
reports            - Pojedyncze raporty (data, tytu≈Ç, link, kurs gie≈Çdowy)
   ‚Üì (FK)
downloaded_files   - Pobrane pliki (PDF/HTML) z MD5, summary_text (LONGTEXT)
                     ‚Üë TO JEST MIEJSCE NA POJEDYNCZE STRESZCZENIA

scheduled_jobs     - Konfiguracje CRON (firma, harmonogram, last_run, run_count)
   ‚Üì (FK)
job_execution_log  - Historia uruchomie≈Ñ (status, czas trwania, b≈Çƒôdy)
   ‚Üì (FK - opcjonalne)
summary_reports    - Zbiorcze raporty MD (≈õcie≈ºka pliku, preview, tagi)

search_history     - Historia rƒôcznych wyszukiwa≈Ñ (u≈ºytkownik, parametry, data)
```

---

## üìã Co Trzeba Zrobiƒá (Konkretne Kroki)

### Prioryt 1: Zapis Pojedynczych Streszcze≈Ñ
**Cel:** Ka≈ºde pojedyncze streszczenie zapisane w bazie.

**Jak:**
1. W `scrape_script.py`, funkcja `get_summaries()`:
   - Dla ka≈ºdego pliku, po wygenerowaniu streszczenia:
   - Znajd≈∫ `file_id` w `downloaded_files` (po `md5_hash` lub `file_name`)
   - Wywo≈Çaj `update_file_summary(file_id, summary_text)`
   
2. `database_connection.py` ju≈º ma funkcjƒô `update_file_summary()` - gotowe!

**Prosta zmiana (~10 linii kodu).**

---

### Prioryt 2: Konwersja Zbiorczego Raportu do PDF
**Cel:** `generate_summary_report()` tworzy PDF zamiast (lub opr√≥cz) MD.

**Opcje:**
- **Opcja A (Prosta):** Markdown ‚Üí PDF
  - Biblioteka: `markdown` + `pdfkit` (wymaga `wkhtmltopdf`)
  - Lub: `markdown` + `weasyprint` (pure Python, lepsze formatowanie)
  
- **Opcja B (Bardziej kontroli):** Bezpo≈õrednio PDF
  - Biblioteka: `reportlab` (niskopoziomowe, pe≈Çna kontrola)
  - Lub: `fpdf2` (prostsze API)

**Rekomendacja:** Opcja A z `weasyprint` - przyjazna, obs≈Çuguje CSS, ≈Çadne PDF-y.

**Kod (~30 linii):**
```python
# W scrape_script.py, po zapisaniu .md:
import markdown
from weasyprint import HTML

# Konwertuj MD ‚Üí HTML
with open(filepath_md, 'r', encoding='utf-8') as f:
    md_text = f.read()
html_text = markdown.markdown(md_text, extensions=['tables'])

# HTML ‚Üí PDF
filepath_pdf = filepath_md.replace('.md', '.pdf')
HTML(string=html_text).write_pdf(filepath_pdf)

# Aktualizuj bazƒô: file_format='pdf', file_path=filepath_pdf
```

---

### Prioryt 3: META-ANALIZA (dla Trybu 2)
**Cel:** Gdy ‚â•2 du≈ºe streszczenia ‚Üí automatycznie generuj meta-raport.

**Jak:**
1. Nowa funkcja w `scrape_script.py` lub osobny plik `meta_analysis.py`:
   ```python
   def generate_meta_report(company: str, model_name: str):
       # 1. Pobierz wszystkie summary_reports dla company z bazy
       reports = get_summary_reports(company=company, limit=100)
       
       # 2. Je≈õli < 2, return (za ma≈Ço danych)
       if len(reports) < 2:
           return None
       
       # 3. Wczytaj tre≈õƒá ka≈ºdego raportu (z file_path)
       summaries_text = []
       for report in reports:
           with open(report['file_path'], 'r') as f:
               summaries_text.append(f.read())
       
       # 4. Skleiƒá wszystko i wys≈Çaƒá do LLM
       combined = "\n\n---\n\n".join(summaries_text)
       prompt = f"Przeanalizuj poni≈ºsze raporty z {company} i opisz trend: jak wiedzie siƒô firmie w czasie?\n\n{combined}"
       
       # 5. Wywo≈Çaj LLM (podobnie jak w summary.py)
       llm = ChatOllama(model=model_name, temperature=0, num_predict=1500)
       response = llm.invoke(prompt)
       meta_summary = response.content
       
       # 6. Zapisz jako PDF + baza (podobnie jak generate_summary_report)
       save_meta_report_to_pdf(company, meta_summary, model_name)
   ```

2. Wywo≈Çanie:
   - **Opcja A:** W `run_scheduled.py`, po ka≈ºdym sukcesie sprawd≈∫ liczbƒô raport√≥w i wywo≈Çaj `generate_meta_report()`
   - **Opcja B:** Osobne zadanie CRON (np. raz w miesiƒÖcu)
   - **Opcja C:** Przycisk w UI "Wygeneruj meta-analizƒô"

**Rekomendacja:** Opcja A (automatycznie po ka≈ºdym CRON) + Opcja C (rƒôcznie w UI).

**Kod (~50-80 linii).**

---

## üõ†Ô∏è Rekomendacje Implementacji (Priorytet i Prostota)

### Faza 1: Minimum Viable Product (MVP) - **2-3 godziny pracy**
1. ‚úÖ **Prioryt 1** - Zapis pojedynczych streszcze≈Ñ do bazy (~10 linii)
2. ‚úÖ **Prioryt 2** - Konwersja MD ‚Üí PDF (~30 linij + instalacja `weasyprint`)

Po Fazie 1: **Oba tryby (manualny + CRON) dzia≈ÇajƒÖ zgodnie z wymaganiami, PDF-y sƒÖ generowane.**

---

### Faza 2: Advanced Feature - **1-2 godziny pracy**
3. ‚úÖ **Prioryt 3** - META-ANALIZA (~50-80 linii + przycisk w UI)

Po Fazie 2: **Pe≈Çna funkcjonalno≈õƒá, w tym analiza trend√≥w sp√≥≈Çki w czasie.**

---

### Faza 3: Polishing (opcjonalnie) - **1 godzina pracy**
- Lepsze formatowanie PDF (CSS dla weasyprint)
- Email powiadomienia (ju≈º jest `config.email_notify`, tylko dodaƒá wysy≈Çkƒô)
- UI: podglƒÖd pojedynczych streszcze≈Ñ w zak≈Çadce "Zbiorcze Raporty"
- Archiwizacja starych raport√≥w (auto-delete po 90 dniach)

---

## üö® Potencjalne Problemy i RozwiƒÖzania

### Problem 1: Rozmiar bazy danych (LONGTEXT w `summary_text`)
- **Symptom:** Pojedyncze streszczenia mogƒÖ byƒá du≈ºe (200-500 s≈Ç√≥w √ó 100 plik√≥w = 50KB-200KB na raport)
- **RozwiƒÖzanie:** LONGTEXT w MySQL obs≈Çuguje do 4GB - wystarczy na lata danych

### Problem 2: Czas generowania meta-analizy
- **Symptom:** LLM musi przetworzyƒá wiele du≈ºych streszcze≈Ñ ‚Üí mo≈ºe trwaƒá 2-5 minut
- **RozwiƒÖzanie:** 
  - Uruchamiaƒá meta-analizƒô asynchronicznie (osobny proces)
  - Pokazaƒá u≈ºytkownikowi "Generowanie... proszƒô czekaƒá"
  - Opcjonalnie: limitowaƒá liczbƒô raport√≥w (np. ostatnie 10)

### Problem 3: Formatowanie PDF
- **Symptom:** Tabele z Markdown mogƒÖ siƒô ≈∫le renderowaƒá w PDF
- **RozwiƒÖzanie:** 
  - U≈ºyƒá `weasyprint` + CSS do stylowania
  - Lub: zamieniƒá tabele na listy punktowane w MD przed konwersjƒÖ

### Problem 4: Deduplikacja w CRON
- **Symptom:** Ten sam raport mo≈ºe byƒá pobrany dwa razy (je≈õli CRON uruchomi siƒô dwa razy tego samego dnia)
- **RozwiƒÖzanie:** **Ju≈º rozwiƒÖzane!** - MD5 hash w `downloaded_files` blokuje duplikaty

---

## üìä Metryki Sukcesu (Jak Sprawdziƒá, ≈ªe Dzia≈Ça)

### Test Tryb 1 (Manualny):
1. ‚úÖ Wpisz "Asseco", data "01-11-2025", pobierz PDF
2. ‚úÖ Sprawd≈∫ `SUMMARY_REPORTS/` - jest plik **PDF** z nazwƒÖ `Asseco_TIMESTAMP_summary.pdf`
3. ‚úÖ Otw√≥rz PDF - zawiera:
   - Metadatƒô (firma, daty, liczba raport√≥w)
   - Listƒô raport√≥w (tabela)
   - Wszystkie pojedyncze streszczenia (po jednym na plik)
4. ‚úÖ Sprawd≈∫ bazƒô:
   - `downloaded_files`: kolumna `summary_text` wype≈Çniona dla ka≈ºdego pliku
   - `summary_reports`: nowy rekord z `file_format='pdf'`, `file_path` wskazuje na PDF

### Test Tryb 2 (CRON):
1. ‚úÖ Utw√≥rz konfiguracjƒô "asseco_test" w UI (harmonogram: */5 * * * * - co 5 minut)
2. ‚úÖ Kliknij "Zainstaluj do crontab"
3. ‚úÖ Poczekaj 5 minut
4. ‚úÖ Sprawd≈∫ `scheduled_results/` - nowy plik tekstowy z wynikami
5. ‚úÖ Sprawd≈∫ `logs/asseco_test.log` - logi wykonania
6. ‚úÖ Sprawd≈∫ bazƒô:
   - `job_execution_log`: nowy rekord ze statusem 'success'
   - `summary_reports`: nowy PDF wygenerowany

### Test META-ANALIZA:
1. ‚úÖ Uruchom CRON dwa razy (lub manualnie dwa razy dla tej samej firmy, r√≥≈ºne daty)
2. ‚úÖ Sprawd≈∫ `summary_reports` - sƒÖ ‚â•2 rekordy dla firmy
3. ‚úÖ Kliknij "Wygeneruj meta-analizƒô" (lub poczekaj na auto)
4. ‚úÖ Nowy PDF z meta-analizƒÖ w `SUMMARY_REPORTS/META/`
5. ‚úÖ PDF zawiera: analizƒô trendu, por√≥wnanie raport√≥w, wnioski o stanie firmy

---

## üéØ Podsumowanie - Co Rozumiem

### Stan Obecny:
- **80-90% funkcjonalno≈õci ju≈º dzia≈Ça**
- Scraping, LLM, baza danych, CRON, UI - wszystko jest
- Brakuje g≈Ç√≥wnie: **PDF zamiast MD**, **zapis pojedynczych streszcze≈Ñ do bazy**, **meta-analiza**

### Co Trzeba Dodaƒá:
1. **~10 linii kodu** - zapis streszcze≈Ñ do `downloaded_files.summary_text`
2. **~30 linii kodu** - konwersja MD ‚Üí PDF (`weasyprint`)
3. **~50-80 linii kodu** - meta-analiza (opcjonalne, ale warto≈õciowe)

### Moja Ocena:
- **To NIE jest rocket science** - sƒÖ to proste rozszerzenia istniejƒÖcego kodu
- **Projekt jest dobrze zorganizowany** - wszystkie elementy sƒÖ na miejscu
- **Baza danych v2.0 jest przygotowana** - `summary_text` w `downloaded_files` ju≈º czeka

### Kluczowe Decyzje Do Podjƒôcia:
1. **Biblioteka do PDF:** `weasyprint` (moja rekomendacja) vs `reportlab` vs `pdfkit`?
2. **Gdzie zapisaƒá pojedyncze streszczenia:**
   - Tylko baza (`downloaded_files.summary_text`) ‚Üê **REKOMENDACJA**
   - Tylko pliki `.md` (folder `SUMMARY_REPORTS/single/`)
   - Oba miejsca (redundancja, ale bezpieczne)
3. **Kiedy uruchamiaƒá meta-analizƒô:**
   - Automatycznie po ka≈ºdym CRON (je≈õli ‚â•2 raporty) ‚Üê **REKOMENDACJA**
   - Osobne zadanie CRON (np. raz w miesiƒÖcu)
   - Tylko rƒôcznie w UI

---

## ‚úÖ Nastƒôpne Kroki (Po Porozumieniu)

### Krok 1: Potwierdzenie Zrozumienia
- Przeczytaj ten dokument
- Potwierd≈∫, ≈ºe rozumiemy problem tak samo
- Zdecyduj o kluczowych wyborach (PDF lib, meta-analiza trigger)

### Krok 2: Implementacja (Po Twojej Akceptacji)
- Zaimplementujƒô zmiany w kolejno≈õci priorytetu
- Bƒôdƒô pisa≈Ç **minimalny kod** (bez nadmiaru)
- Bƒôdƒô testowa≈Ç ka≈ºdƒÖ zmianƒô przed przej≈õciem dalej

### Krok 3: Testy
- Przetestujemy razem oba tryby
- Sprawdzimy PDF-y
- Zweryfikujemy bazƒô

---

## üí¨ Pytania Do Ciebie

1. **Czy tak rozumiesz problem jak ja opisa≈Çem?**
2. **Czy wyb√≥r `weasyprint` dla PDF jest OK?** (alternatywnie: `reportlab`)
3. **Pojedyncze streszczenia - tylko baza czy te≈º pliki `.md`?** (polecam: tylko baza)
4. **Meta-analiza - automatycznie po ka≈ºdym CRON czy rƒôcznie w UI?** (polecam: oba)
5. **Czy masz inne uwagi lub pytania?**

---

**Gdy odpowiesz na powy≈ºsze pytania, zacznƒô implementacjƒô. Bƒôdƒô dzia≈Ça≈Ç ma≈Çymi krokami, testujƒÖc ka≈ºdy krok, i informujƒÖc Ciƒô o postƒôpach.**
